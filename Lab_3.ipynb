{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773c9164-a214-49f3-9957-3dd7ac1973fc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  Lab 3: Encuentra tu Destino So√±ado  \n",
    "## Construyendo un Planificador de Viajes con LangGraph usando herramientas\n",
    "\n",
    "---\n",
    "\n",
    "##  ¬øDe qu√© trata este laboratorio?\n",
    "\n",
    "En este lab vamos a crear un **agente inteligente** que te ayuda a encontrar **el mejor lugar para tus pr√≥ximas vacaciones**.  \n",
    "Pero no ser√° un simple chatbot: vamos a ense√±arle a **buscar informaci√≥n real** y **usar herramientas** para mejorar sus respuestas.  \n",
    "Aqu√≠ aprender√°s a conectar modelos de lenguaje con herramientas externas usando LangGraph.\n",
    "\n",
    "---\n",
    "\n",
    "##  ¬øQu√© har√° el agente?\n",
    "\n",
    "- Podr√°s chatear con √©l como si fuera tu asesor de viajes.\n",
    "- Le pedir√°s recomendaciones y, **basado en tu perfil** o en **datos hist√≥ricos de otros viajeros**, te sugerir√° lugares.\n",
    "- Adem√°s, buscar√° **informaci√≥n adicional** sobre esos destinos para que tengas m√°s detalles.\n",
    "\n",
    "---\n",
    "\n",
    "##  ¬øQu√© cosas t√©cnicas vamos a practicar?\n",
    "\n",
    "- **Crear agentes personalizados** usando LangGraph.\n",
    "- **Conectar** esos agentes a **bases de datos vectoriales** para encontrar informaci√≥n parecida (lo que se llama **RAG: Retrieval Augmented Generation**).\n",
    "- **Configurar tipos de agentes**: unos que planean solitos y otros que piden permiso antes de actuar (**Human-In-The-Loop**).\n",
    "- Entender c√≥mo trabajan distintos **tipos de agentes**, como:\n",
    "  - Agentes que **planean sin necesidad de ver resultados** (ReWOO)\n",
    "  - Agentes que **razonan y act√∫an paso a paso** (ReACT)\n",
    "\n",
    "---\n",
    "\n",
    "##  ¬øC√≥mo ser√° la interacci√≥n?\n",
    "\n",
    "Imagina que escribes:  \n",
    "_\"Quiero un destino tranquilo, playa, poca gente...\"_\n",
    "\n",
    "1. El agente **busca en el historial de viajes** de otros usuarios que pidieron cosas similares.\n",
    "2. Te recomienda un lugar (por ejemplo, alguna playa escondida en Costa Rica üèñÔ∏è).\n",
    "3. Luego, **busca m√°s detalles** sobre ese lugar para que tengas informaci√≥n como clima, mejores fechas para viajar, etc.\n",
    "\n",
    "Y si configuramos modo \"Human-in-the-loop\", antes de hacer algo importante te preguntar√°:  \n",
    "_\"¬øQuieres que busque m√°s informaci√≥n sobre este lugar?\"_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16c384-4302-4e88-8aa6-878df4e394db",
   "metadata": {},
   "source": [
    "<img src=\"images/descarga_l3_1.png\" width=\"1000\" height=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04dc437-40cc-4f36-9a9c-98764586c163",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  Agentes\n",
    "\n",
    "Un **agente de IA** es un programa o sistema que **percibe su entorno, toma decisiones y ejecuta acciones** para alcanzar ciertos objetivos, usando t√©cnicas de inteligencia artificial.  \n",
    "Est√°n dise√±ados para trabajar **de manera aut√≥noma** y **adaptarse** con base en la informaci√≥n y experiencias que reciben.  \n",
    "No se limitan a interacciones simples: pueden tomar decisiones complejas, resolver problemas y completar tareas, **con o sin intervenci√≥n humana**.\n",
    "\n",
    "### Caracter√≠sticas principales:\n",
    "- **Percepci√≥n:** Captan informaci√≥n del entorno (sensores, datos, etc.).\n",
    "- **Toma de decisiones:** Procesan datos y eligen la mejor acci√≥n.\n",
    "- **Acci√≥n:** Ejecutan decisiones e interact√∫an con el entorno o usuarios.\n",
    "- **Aprendizaje:** Mejoran su desempe√±o con experiencia y retroalimentaci√≥n.\n",
    "- **Autonom√≠a:** Funcionan de manera independiente en muchos casos.\n",
    "- **Orientaci√≥n a objetivos:** Siempre trabajan buscando cumplir metas espec√≠ficas.\n",
    "\n",
    "---\n",
    "\n",
    "# Relaci√≥n con los LLMs\n",
    "\n",
    "Los **Modelos de Lenguaje** (LLMs) son excelentes resolviendo problemas de clasificaci√≥n, lo que ha hecho posible **crear agentes de IA** verdaderamente √∫tiles.\n",
    "\n",
    "En este caso, **creamos un cliente de Bedrock** que nos permite **configurar y utilizar un LLM** en LangChain, espec√≠ficamente sobre AWS Bedrock.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41832d91-5c82-4c48-b81d-7fb2d1b0d046",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Antes de empezar, instala las dependencias:\n",
    "\n",
    "- Si solo necesitas paquetes de Python:\n",
    "  \n",
    "  ```bash\n",
    "  pip install -r requirements.txt\n",
    "  ```\n",
    "\n",
    "- Si tambi√©n necesitas preparar el sistema:\n",
    "\n",
    "  ```bash\n",
    "  bash provisionar.sh\n",
    "  ```\n",
    "\n",
    "Este script instala herramientas del sistema y despu√©s los paquetes de Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126caeb3-10ef-45e3-b2d8-9148824599de",
   "metadata": {},
   "source": [
    "\n",
    "#  Modelo de Lenguaje\n",
    "\n",
    "El **modelo de lenguaje** (LLM) que usaremos en este laboratorio para todos nuestros agentes ser√° **Claude 3 Sonnet** a trav√©s de **Amazon Bedrock**.  \n",
    "Para facilitar su uso, emplearemos la clase **`ChatBedrockConverse`** de **LangChain**, que es un **wrapper** (envoltorio) que simplifica la interacci√≥n con la API **Converse** de Bedrock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98b85df-1885-44ed-b5f5-50c7712558e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "import boto3\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# ---- ‚ö†Ô∏è Actualiza la regi√≥n para tu configuraci√≥n de AWS ‚ö†Ô∏è ----\n",
    "region = 'us-east-2'\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region,\n",
    ")\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "\n",
    "model_id = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=model_id,\n",
    "    temperature=0,\n",
    "    max_tokens=5000,\n",
    "    client=bedrock_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c95b4-cddb-4780-b7b0-f5776a8566a9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Construcci√≥n de nuestro primer agente de recomendaciones de viaje\n",
    "\n",
    "### Herramientas\n",
    "\n",
    "Vamos a crear herramientas que nuestros agentes usar√°n para encontrar un destino de vacaciones basado en el perfil del usuario y en el historial de viaje de usuarios similares.\n",
    "\n",
    "Las herramientas son recursos externos, servicios o APIs que un agente LLM puede acceder y utilizar para ampliar sus capacidades y realizar tareas espec√≠ficas. Estas herramientas permiten que el agente vaya m√°s all√° del simple procesamiento de lenguaje, logrando interactuar con sistemas externos, recuperar informaci√≥n o ejecutar acciones que normalmente estar√≠an fuera de su alcance. Gracias a esto, los agentes LLM pueden ofrecer soluciones mucho m√°s completas y pr√°cticas a las solicitudes de los usuarios.\n",
    "\n",
    "Una herramienta est√° compuesta por:\n",
    "\n",
    "- El nombre de la herramienta.\n",
    "- Una descripci√≥n de lo que hace.\n",
    "- Un esquema JSON que define los datos de entrada.\n",
    "- Una funci√≥n (y opcionalmente su versi√≥n as√≠ncrona).\n",
    "\n",
    "En LangGraph, las herramientas se crean decorando funciones con `@tool`. Este decorador toma el nombre de la funci√≥n, sus docstrings y sus par√°metros de entrada, y los convierte autom√°ticamente en un nombre, una descripci√≥n y una definici√≥n de interfaz que el modelo puede entender. Una vez que las herramientas est√°n disponibles para el modelo, este puede decidir c√≥mo y cu√°ndo invocarlas, dependiendo de las instrucciones y necesidades.\n",
    "\n",
    "### Nuestro primer caso\n",
    "\n",
    "Vamos a construir una herramienta que utilice datos hist√≥ricos de viajes de diferentes usuarios para encontrar un destino adecuado bas√°ndose en el perfil de cada usuario y en el historial de personas similares.\n",
    "\n",
    "Esta herramienta leer√° un archivo CSV local que contiene informaci√≥n hist√≥rica de destinos de viaje. Analizar√° esos datos y devolver√° el destino m√°s popular para ese usuario.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "Usaremos dos conjuntos de datos:\n",
    "\n",
    "1. Un primer dataset con columnas clave como: Id, Localizaci√≥n actual, Destinos de viaje pasados, N√∫mero de viajes, Ciudad de llegada, entre otras. Estos datos se integrar√°n en el sistema RAG para ayudar a identificar destinos similares.\n",
    "   \n",
    "2. Un segundo dataset con detalles de ciudades, incluyendo lugares tur√≠sticos populares. Usaremos este conjunto para encontrar destinos similares a trav√©s de b√∫squedas sem√°nticas apoyadas en un vector store.\n",
    "\n",
    "Primero encontraremos las ciudades posibles donde el usuario podr√≠a viajar, y luego buscaremos otros destinos similares utilizando la tecnolog√≠a de b√∫squeda vectorial.\n",
    "\n",
    "Ahora vamos a crear nuestra primera herramienta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cccbaf8-deed-469e-a517-1f759b485130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "def read_travel_data(file_path: str = \"data/synthetic_travel_data.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Leer datos de viajes desde un archivo CSV.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        # Si no se encuentra el archivo, retorna un DataFrame vac√≠o con columnas predefinidas\n",
    "        return pd.DataFrame(\n",
    "            columns=[\"Id\", \"Name\", \"Current_Location\", \"Age\", \"Past_Travel_Destinations\",\n",
    "                     \"Number_of_Trips\", \"Flight_Number\", \"Departure_City\", \"Arrival_City\", \"Flight_Date\"]\n",
    "        )\n",
    "\n",
    "@tool\n",
    "def compare_and_recommend_destination(config: RunnableConfig) -> str:\n",
    "    \"\"\"Esta herramienta se utiliza para verificar a qu√© destinos ha viajado el usuario.\n",
    "    Esta herramienta ya recibe el user_id. Usa el ID de usuario para buscar su informaci√≥n.\n",
    "    Si el usuario ya ha visitado una ciudad, no se debe recomendar de nuevo esa ciudad.\n",
    "\n",
    "    Retorna:\n",
    "        str: Destino recomendado.\n",
    "    \"\"\"\n",
    "\n",
    "    # Leer el dataset de viajes\n",
    "    df = read_travel_data()\n",
    "\n",
    "    # Obtener el user_id desde la configuraci√≥n\n",
    "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
    "\n",
    "    # Verificar si el usuario existe en el dataset\n",
    "    if user_id not in df[\"Id\"].values:\n",
    "        return \"Usuario no encontrado en la base de datos de viajes.\"\n",
    "\n",
    "    # Extraer la informaci√≥n del usuario\n",
    "    user_data = df[df[\"Id\"] == user_id].iloc[0]\n",
    "    current_location = user_data[\"Current_Location\"]\n",
    "    age = user_data[\"Age\"]\n",
    "    past_destinations = user_data[\"Past_Travel_Destinations\"].split(\", \")\n",
    "\n",
    "    # Buscar usuarios similares (misma ubicaci√≥n actual y edad aproximada ¬±5 a√±os)\n",
    "    similar_users = df[\n",
    "        (df[\"Current_Location\"] == current_location) &\n",
    "        (df[\"Age\"].between(age - 5, age + 5))\n",
    "    ]\n",
    "\n",
    "    # Obtener todos los destinos pasados de usuarios similares\n",
    "    all_destinations = [\n",
    "        dest\n",
    "        for user_dests in similar_users[\"Past_Travel_Destinations\"].str.split(\", \")\n",
    "        for dest in user_dests\n",
    "    ]\n",
    "\n",
    "    # Contar cu√°ntas veces aparece cada destino\n",
    "    destination_counts = Counter(all_destinations)\n",
    "\n",
    "    # Eliminar de las recomendaciones la ubicaci√≥n actual y los destinos ya visitados\n",
    "    for dest in [current_location] + past_destinations:\n",
    "        if dest in destination_counts:\n",
    "            del destination_counts[dest]\n",
    "\n",
    "    # Si no hay nuevos destinos para recomendar\n",
    "    if not destination_counts:\n",
    "        return f\"No se encontraron nuevas recomendaciones para usuarios en {current_location} con edad similar.\"\n",
    "\n",
    "    # Seleccionar el destino m√°s popular\n",
    "    recommended_destination = destination_counts.most_common(1)[0][0]\n",
    "\n",
    "    return (f\"Basado en tu ubicaci√≥n actual ({current_location}), edad ({age}) \"\n",
    "            f\"y tu historial de viajes, te recomendamos visitar {recommended_destination}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3021c64-54e1-4cd3-96e5-8bfffada919d",
   "metadata": {},
   "source": [
    "\n",
    "La segunda herramienta que queremos agregar a nuestro agente de recomendaci√≥n de viajes es una **herramienta de recuperaci√≥n de informaci√≥n**. Esta herramienta permitir√° que el agente acceda a datos externos y los utilice para enriquecer su base de conocimientos. Gracias a esto, el agente podr√° ofrecer recomendaciones m√°s precisas y detalladas.\n",
    "\n",
    "Contamos con un conjunto de datos sint√©ticos que contiene informaci√≥n sobre algunas ciudades del mundo. Utilizaremos estos datos para poblar nuestra base de conocimiento con informaci√≥n adicional acerca de cada ciudad.\n",
    "\n",
    "En esta secci√≥n prepararemos nuestro sistema de recuperaci√≥n (**retriever**):\n",
    "\n",
    "- Vamos a utilizar archivos `pickle` que ya est√°n preparados y contienen una **vector store**.\n",
    "- La **vector store** es una base de datos que almacena representaciones num√©ricas (vectores) de la informaci√≥n, lo que permite hacer b√∫squedas sem√°nticas r√°pidas y eficientes.\n",
    "- El proceso de carga y uso de esta vector store es similar al esquema que se muestra a continuaci√≥n (no incluido aqu√≠, pero se refiere a cargar los vectores, realizar b√∫squedas y devolver los resultados relevantes).\n",
    "\n",
    "Esta herramienta har√° posible que nuestro agente busque ciudades similares o actividades relacionadas bas√°ndose en el contexto del usuario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb57dad-95ed-446b-a725-18cf15f056aa",
   "metadata": {},
   "source": [
    "<img src=\"images/RAG-travellers.png\" width=\"1000\" height=\"600\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722b3de4-e6dd-487b-992e-79e2c93c8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de bibliotecas necesarias para trabajar con embeddings, vector stores y recuperaci√≥n de documentos\n",
    "from langchain_aws.embeddings.bedrock import BedrockEmbeddings  # Embeddings de Bedrock de AWS\n",
    "from langchain.retrievers import ParentDocumentRetriever  # Recuperador de documentos relacionados\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Divisor de texto para separar en fragmentos peque√±os\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from io import BytesIO  # Para manejar datos binarios en memoria\n",
    "import pickle  # Para cargar objetos serializados\n",
    "\n",
    "# Modelo de embeddings que utiliza Bedrock para obtener representaciones vectoriales de texto\n",
    "embeddings_model = BedrockEmbeddings(\n",
    "    client=bedrock_client, model_id=\"amazon.titan-embed-text-v1\"  # Cliente de Bedrock y modelo de embeddings\n",
    ")\n",
    "\n",
    "# Definici√≥n de un divisor de texto que divide el texto en fragmentos, considerando ciertos delimitadores y tama√±os\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\", \"\\n\\n\"],  # Delimitadores para dividir el texto (salto de l√≠nea simple y doble)\n",
    "    chunk_size=2000,  # Tama√±o m√°ximo de cada fragmento de texto\n",
    "    chunk_overlap=250  # Superposici√≥n entre fragmentos consecutivos\n",
    ")\n",
    "\n",
    "# Archivos que contienen el store en memoria y el vector store (almacenamiento de vectores)\n",
    "in_memory_store_file = \"data/section_doc_store.pkl\"  # Archivo que contiene el store de documentos\n",
    "vector_store_file = \"data/section_vector_store.pkl\"  # Archivo que contiene el vector store\n",
    "\n",
    "# Carga del store en memoria desde el archivo\n",
    "store = pickle.load(open(in_memory_store_file, \"rb\"))\n",
    "\n",
    "# Carga del vector store desde el archivo y deserializaci√≥n de los datos\n",
    "vector_db_buff = BytesIO(pickle.load(open(vector_store_file, \"rb\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfaa172d-d521-440d-8e92-c8a3f9e7e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vector_db = FAISS.deserialize_from_bytes(\n",
    "    serialized=vector_db_buff.read(),  # Datos serializados que representan el vector store\n",
    "    embeddings=embeddings_model,  # Modelo de embeddings utilizado para deserializar\n",
    "    allow_dangerous_deserialization=True,  # Permite deserializar de forma peligrosa si es necesario\n",
    ")\n",
    "\n",
    "# Definici√≥n de un recuperador de documentos principales (parent documents) que utiliza el vector store y el store de documentos\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vector_db,  # Vector store utilizado para la b√∫squeda de documentos\n",
    "    docstore=store,  # Store de documentos donde se almacenan los datos\n",
    "    child_splitter=child_splitter,  # Divisor de texto utilizado para fragmentar los documentos\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589a41b-dc0c-4d06-a221-f00e0df4d912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e5ea57e-32c3-492a-8d39-8de81c0c9669",
   "metadata": {},
   "source": [
    "¬ø Que hace est√© c√≥digo ?\n",
    "Definici√≥n: \n",
    "Un **VectorStore** es una estructura que guarda representaciones num√©ricas (vectores) de textos, generadas por un modelo de embeddings, para poder hacer b√∫squedas por similitud (por ejemplo, encontrar qu√© textos se parecen a una pregunta del usuario). Por otro lado, un **DocStore** guarda los documentos originales completos, como si fuera una biblioteca, y se usa para recuperar el contenido real cuando ya sabes qu√© parte es relevante seg√∫n la b√∫squeda en el VectorStore. En resumen: el VectorStore te dice *qu√©* documento es relevante, y el DocStore te da el *contenido completo* de ese documento.\n",
    "\n",
    "Dado lo anterior el c√≥digo hace lo siguiente:\n",
    "\n",
    "1. **Crea un modelo de embeddings con Bedrock** (Amazon Titan) para convertir texto en vectores, que luego servir√°n para buscar por similitud.\n",
    "2. **Define c√≥mo partir el texto en fragmentos** usando saltos de l√≠nea como separadores, con fragmentos de hasta 2000 caracteres y con 250 de solapamiento.\n",
    "3. **Carga desde disco dos archivos:** uno con los documentos originales (`DocStore`) y otro con sus representaciones vectoriales (`VectorStore`), ambos previamente guardados.\n",
    "4. **Deserializa el VectorStore** usando el modelo de embeddings, para dejarlo listo para hacer b√∫squedas por similitud sem√°ntica.\n",
    "5. **Crea un \"retriever\"**, que es el componente que, cuando recibe una consulta, busca en el `VectorStore` qu√© fragmentos son relevantes y luego va al `DocStore` para traer los documentos completos relacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130bbf59-f5c3-4bfc-986b-bff5c44dda92",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ahora creamos una herramienta especializada de recuperaci√≥n utilizando la funci√≥n `create_retriever_tool` de LangChain:\n",
    "\n",
    "- La herramienta se basa en el *retriever* que configuramos previamente.  \n",
    "- La nombramos **\"search_user_interest\"**.  \n",
    "- Su descripci√≥n indica que realiza b√∫squedas en m√∫ltiples documentos PDF que contienen informaci√≥n sobre distintas ciudades.  \n",
    "- Est√° dise√±ada para encontrar datos que coincidan con los intereses del usuario en relaci√≥n a diversas ciudades.  \n",
    "- La b√∫squeda se limita √∫nicamente a las palabras clave mencionadas en la entrada del usuario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496f2b6-4ce3-42ec-bc20-d9c0d63fb233",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e47b899-2a9a-417d-aef2-c33a951ca636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool  # Importa la funci√≥n para crear una herramienta de recuperaci√≥n\n",
    "\n",
    "# Crea una herramienta de b√∫squeda sem√°ntica usando un retriever ya definido\n",
    "\n",
    "description = \"\"\"\n",
    " Searches through multiple PDF documents containing city details to find information matching \n",
    "    the user's interests in various cities. Only search based on the keyword mentioned in user input.\n",
    "\"\"\"\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,                         # Objeto que realiza la b√∫squeda en documentos vectorizados\n",
    "    \"search_user_interest\",           # Nombre identificador de la herramienta\n",
    "     description # Descripci√≥n funcional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf217ffd-1421-4ba7-9e67-51ae5c24bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [compare_and_recommend_destination, retriever_tool]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505c6da-47ab-44ea-9a44-9c3989e68a79",
   "metadata": {},
   "source": [
    "### üîç ¬øQu√© hace este c√≥digo?\n",
    "\n",
    "Este c√≥digo crea una **herramienta de recuperaci√≥n de informaci√≥n sem√°ntica** basada en un `retriever` de LangChain. Esta herramienta permite buscar texto relacionado con una consulta (por ejemplo, del usuario) dentro de documentos previamente indexados, como PDFs sobre ciudades. Esta herramienta se puede usar en un agente o sistema conversacional para responder preguntas autom√°ticamente usando ese conocimiento.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è ¬øQu√© es `create_retriever_tool`?\n",
    "\n",
    "`create_retriever_tool` es una funci√≥n de `langchain.tools.retriever` que **convierte un retriever en una herramienta LangChain-compatible**, es decir, algo que un agente puede usar autom√°ticamente para responder preguntas bas√°ndose en documentos vectorizados.\n",
    "\n",
    "---\n",
    "\n",
    "### üì• Par√°metros que recibe:\n",
    "\n",
    "```python\n",
    "create_retriever_tool(\n",
    "    retriever,                # (obligatorio) Objeto que implementa el m√©todo `.get_relevant_documents(query)`\n",
    "    \"search_user_interest\",   # (obligatorio) Nombre √∫nico de la herramienta, usado por el agente\n",
    "    \"Descripci√≥n funcional\"   # (obligatorio) Explicaci√≥n de qu√© hace la herramienta para ayudar a LLM a decidir cu√°ndo usarla\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47620981-1396-43e4-9787-e42a0a58cd57",
   "metadata": {},
   "source": [
    "Ahora tambi√©n agregamos ambas herramientas a la lista de herramientas que nuestro agente podr√° usar.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706464c-6373-4091-970e-83559c76c481",
   "metadata": {},
   "source": [
    "**Tipos de Agentes**  \n",
    "Los agentes se componen de dos elementos principales: los *Planificadores*, que crean un plan detallado para la ejecuci√≥n de tareas, y los *Solucionadores*, que ejecutan los pasos planificados e integran los resultados de las tareas ejecutadas para formular una respuesta final. Estos dos componentes trabajan en conjunto para llevar a cabo una tarea espec√≠fica. Esto implica lo siguiente:\n",
    "\n",
    "De manera general, existen dos tipos de agentes:\n",
    "\n",
    "- **Agentes ReWoO / ROC**: Son agentes que conocen las herramientas disponibles, pero devuelven el control al usuario. La t√©cnica *ReWoO* optimiza el rendimiento generando un plan completo de tareas desde el inicio y ejecut√°ndolo sin verificar los resultados intermedios, como se muestra en las figuras a continuaci√≥n. Esta estrategia reduce la latencia total al minimizar las llamadas al modelo. Es especialmente √∫til para ejecuciones as√≠ncronas, confirmaciones, intervenciones humanas, entre otros. En este enfoque, el agente devuelve todo el plan de ejecuci√≥n a la aplicaci√≥n que lo invoc√≥, por ejemplo: \"invoca esta herramienta, seguida de esta otra\", etc. Sin embargo, esto requiere un *prompt* muy complejo. Adem√°s, si los resultados intermedios debieran modificar el orden de los pasos, esta estrategia no lo contempla y puede fallar.\n",
    "\n",
    "- **Agentes ReACT**: Son agentes que reaccionan al est√≠mulo recibido, como puede ser una respuesta de una herramienta, una entrada del usuario, una respuesta del modelo, una invocaci√≥n de herramienta, entre otros. La estrategia *ReACT* por defecto requiere al menos N+1 llamadas al modelo para ejecutar N pasos. Sin embargo, es m√°s f√°cil de implementar y ofrece flexibilidad mediante la selecci√≥n din√°mica de herramientas en funci√≥n de la respuesta previa. Para la mayor√≠a de los casos de uso, esta ser√° la estrategia predeterminada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccc7ed-1438-4c37-a0e3-14028b4ea47d",
   "metadata": {},
   "source": [
    "<img src=\"images/ReACT_agents.png\" width=\"300\" height=\"600\">\n",
    "\n",
    "<img src=\"images/ReWoO_agents.png\" width=\"300\" height=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de3358-54e3-4c2d-854e-4379d99e5f90",
   "metadata": {},
   "source": [
    "Steps in a ReACT agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e03df-942f-4f49-ac18-ca6bf2d4119c",
   "metadata": {},
   "source": [
    "<img src=\"images/agent_action_thought.png\" width=\"400\" height=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4580f-39ea-4784-9063-f065bc76d3c4",
   "metadata": {},
   "source": [
    "Crea un agente ReWoO para encontrar un buen destino  \n",
    "\n",
    "LangGraph ofrece un mecanismo sencillo, llamado `bind_tools`, que permite asociar herramientas a una cadena LCEL (LangChain Expression Language) y crear as√≠ agentes que devuelven el control a la aplicaci√≥n llamadora. En este enfoque, el agente no ejecuta directamente las funciones, sino que indica **qu√© funci√≥n se debe llamar y con qu√© par√°metros**. Corresponde entonces a la aplicaci√≥n que lo invoc√≥ **ejecutar la funci√≥n**, agregar la respuesta al historial del prompt, y **volver a llamar al modelo**.\n",
    "\n",
    "Este tipo de agente es especialmente √∫til en flujos **as√≠ncronos (A-Sync)** o cuando se requiere un **humano en el ciclo de decisi√≥n (Human-in-the-loop)**.\n",
    "\n",
    "En flujos con m√∫ltiples pasos donde hay que invocar varias herramientas ‚Äîcomo en este caso‚Äî puede ser muy costoso (en complejidad y control) mantener un bucle de ejecuci√≥n manual hasta que el modelo devuelva una se√±al de parada como respuesta final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551ccdf9-6f85-425e-93da-4126e9e45b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "rewoo_agent = llm.bind_tools(tools)\n",
    "print(type(rewoo_agent))\n",
    "display(Image(rewoo_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d223fd1-9e79-4065-8261-b935937a0f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El LLM respondi√≥ con una llamada a la herramienta: compare_and_recommend_destination() :: par√°metros = {}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Configuraci√≥n que incluye el ID del usuario que est√° interactuando con el agente\n",
    "config = {\"configurable\": {\"user_id\": 918}}\n",
    "\n",
    "# Se env√≠a un mensaje al agente ReWoO solicitando una recomendaci√≥n de destino vacacional\n",
    "response_rewo = rewoo_agent.invoke(\n",
    "    [HumanMessage(content=\"Sugi√©reme un buen destino para vacacionar.\")],\n",
    "    config\n",
    ")\n",
    "\n",
    "\n",
    "# Se recorren los mensajes contenidos en la respuesta\n",
    "for one_message in response_rewo.content:\n",
    "    # Si el mensaje es una instrucci√≥n para llamar a una herramienta\n",
    "    if isinstance(one_message, dict) and one_message['type'] == 'tool_use':\n",
    "        print(f\"El LLM respondi√≥ con una llamada a la herramienta: {one_message['name']}() :: par√°metros = {one_message['input']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36768750-6b66-476d-b5b9-a91c96a6de6b",
   "metadata": {},
   "source": [
    "Este c√≥digo representa una ejecuci√≥n t√≠pica de un agente ReWoO. El modelo no ejecuta la herramienta directamente, sino que indica qu√© herramienta se debe usar y con qu√© par√°metros. Le toca a la aplicaci√≥n (o a ti como desarrollador) realizar la llamada a esa funci√≥n, capturar la respuesta, y volver a alimentar al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee99b2d-253c-45b5-9ee6-60d355f96370",
   "metadata": {},
   "source": [
    "**Crear un Agente ReACT**\n",
    "\n",
    "Para cualquier flujo de trabajo que involucre m√∫ltiples pasos y m√∫ltiples turnos, debemos crear o aprovechar los agentes ReACT. Ahora que hemos definido las herramientas y el LLM, podemos crear el agente. LangGraph viene con APIs preconstruidas de nivel superior para escenarios comunes de agentes. Estas APIs de alto nivel cubren una gran parte del trabajo pesado al construir nuestro *StateGraph* para los casos de uso de agentes. Para el **Enfoque 1**, utilizaremos estas APIs de alto nivel para construir el agente y su *StateGraph*. Luego, para el **Enfoque 2**, utilizaremos APIs de bajo nivel y reconstruiremos lo que la API de alto nivel est√° haciendo detr√°s de escena.\n",
    "\n",
    "Comencemos inicializando el agente con el LLM y las herramientas.\n",
    "\n",
    "Aqu√≠ estamos aprovechando el **ID de usuario** que se pasa a trav√©s de la configuraci√≥n para sugerir destinos similares basados en el historial de viajes. Este diagrama explica la llamada:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1f32349-22eb-4135-a1f4-6447e5c9be17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langgraph.graph.state.CompiledStateGraph"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "react_agent = create_react_agent(\n",
    "    llm, tools, state_modifier=\"You are a helpful assistant capable of providing travel recommendations. Use the provided tools to look for personalized travel recommendations and information about specific destinations.\",\n",
    ")\n",
    "type(react_agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08981ae7-71ba-4922-9ea5-093bfb69ab53",
   "metadata": {},
   "source": [
    "La funci√≥n `create_react_agent` devolvi√≥ un objeto CompiledStateGraph. Vamos a visualizar este gr√°fico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b79dbbe-f8e1-4cab-b833-611477d204f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(react_agent.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985e14d-fc17-4e2f-9ef0-feb449865d4e",
   "metadata": {},
   "source": [
    "Estamos listos para probar nuestro agente con una entrada de ejemplo.\n",
    "\n",
    "Notaremos que el agente har√° varias llamadas a herramientas en las siguientes declaraciones de impresi√≥n, algo como esto: `{'type': 'tool_use', 'name': 'compare_and_recommend_destination', 'input': {'user_name': 'user'}, 'id': 'tooluse_vKrc'}`.\n",
    "\n",
    "Primero, el agente llamar√° a la herramienta `compare_and_recommend_destination` para recomendar un destino. Luego, llamar√° a la herramienta `search_user_interest` para obtener m√°s informaci√≥n sobre el destino sugerido a trav√©s de RAG, para que pueda proporcionar una respuesta con hechos respaldados.\n",
    "\n",
    "La cronolog√≠a completa de las acciones detr√°s de escena es la siguiente:\n",
    "\n",
    "1. El usuario pide una recomendaci√≥n para unas vacaciones de viaje.\n",
    "2. El LLM usa la herramienta `compare_and_recommend_destination` para analizar el perfil del usuario (ubicaci√≥n, edad y datos de viajes pasados) y sugiere una ubicaci√≥n.\n",
    "3. Luego, el LLM usa la herramienta `search_user_interest` para recopilar m√°s informaci√≥n sobre el destino.\n",
    "4. Basado en los resultados de b√∫squeda, el LLM proporciona una respuesta detallada, destacando las atracciones del lugar, que se extraen de los documentos PDF utilizados para crear el recuperador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f35943d-5184-4e9f-8b9d-a7bd0762e21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error raised by inference endpoint\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py\", line 195, in _invoke_model\n",
      "    response = self.client.invoke_model(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py\", line 570, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py\", line 1031, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.\n",
      "Error raised by inference endpoint\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py\", line 195, in _invoke_model\n",
      "    response = self.client.invoke_model(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py\", line 570, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py\", line 1031, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Rastro completo:\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Sugi√©reme un buen destino de vacaciones.\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Voy a ayudarte a encontrar un destino de vacaciones perfecto. Primero, utilizar√© la herramienta para obtener una recomendaci√≥n personalizada.'}, {'type': 'tool_use', 'name': 'compare_and_recommend_destination', 'input': {}, 'id': 'tooluse_9Dlz0-uORw-LHroi3fcPKQ'}]\n",
      "Tool Calls:\n",
      "  compare_and_recommend_destination (tooluse_9Dlz0-uORw-LHroi3fcPKQ)\n",
      " Call ID: tooluse_9Dlz0-uORw-LHroi3fcPKQ\n",
      "  Args:\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: compare_and_recommend_destination\n",
      "\n",
      "Basado en tu ubicaci√≥n actual (Paris), edad (62.0) y tu historial de viajes, te recomendamos visitar Ljubljana.\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': '¬°Qu√© interesante! Me han recomendado Ljubljana, la capital de Eslovenia. Voy a buscar m√°s informaci√≥n sobre esta ciudad para darte m√°s detalles.'}, {'type': 'tool_use', 'name': 'search_user_interest', 'input': {'query': 'Ljubljana turismo'}, 'id': 'tooluse_m_NTZcHqTLqOcWw4JIqdaw'}]\n",
      "Tool Calls:\n",
      "  search_user_interest (tooluse_m_NTZcHqTLqOcWw4JIqdaw)\n",
      " Call ID: tooluse_m_NTZcHqTLqOcWw4JIqdaw\n",
      "  Args:\n",
      "    query: Ljubljana turismo\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_user_interest\n",
      "\n",
      "Error: ValidationException('An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.')\n",
      " Please fix your mistakes.\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Me disculpo por el error t√©cnico. Perm√≠teme intentarlo de nuevo.'}, {'type': 'tool_use', 'name': 'search_user_interest', 'input': {'query': 'Ljubljana tourism'}, 'id': 'tooluse_sJcjNtozSie-fWUWx-isSA'}]\n",
      "Tool Calls:\n",
      "  search_user_interest (tooluse_sJcjNtozSie-fWUWx-isSA)\n",
      " Call ID: tooluse_sJcjNtozSie-fWUWx-isSA\n",
      "  Args:\n",
      "    query: Ljubljana tourism\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_user_interest\n",
      "\n",
      "Error: ValidationException('An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.')\n",
      " Please fix your mistakes.\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Lo siento, parece que hay un problema t√©cnico con la b√∫squeda de informaci√≥n. Sin embargo, puedo compartir contigo algunos detalles sobre Ljubljana bas√°ndome en mi conocimiento:\n",
      "\n",
      "Ljubljana es una ciudad encantadora y poco conocida que ofrece una experiencia √∫nica de viaje:\n",
      "\n",
      "1. Arquitectura y ambiente:\n",
      "- Ciudad peque√±a y pintoresca\n",
      "- Dise√±o urbano influenciado por el arquitecto Jo≈æe Pleƒçnik\n",
      "- Centro hist√≥rico peatonal muy bien conservado\n",
      "\n",
      "2. Atracciones principales:\n",
      "- Castillo de Ljubljana: Una fortaleza medieval con vistas panor√°micas\n",
      "- Puente de los Dragones: Un s√≠mbolo emblem√°tico de la ciudad\n",
      "- Mercado central: Lugar perfecto para probar la gastronom√≠a local\n",
      "\n",
      "3. Entorno natural:\n",
      "- Rodeada de naturaleza impresionante\n",
      "- Cerca del Lago Bled, uno de los lugares m√°s hermosos de Europa\n",
      "- F√°cil acceso a parques nacionales y paisajes monta√±osos\n",
      "\n",
      "4. Ventajas para el viajero:\n",
      "- Destino menos tur√≠stico, lo que significa menos multitudes\n",
      "- Precios m√°s econ√≥micos comparados con otras capitales europeas\n",
      "- Gente amable y ambiente relajado\n",
      "- Excelente gastronom√≠a con influencias austriacas, italianas y balc√°nicas\n",
      "\n",
      "5. Clima:\n",
      "- Veranos suaves y agradables\n",
      "- Inviernos moderados\n",
      "- Ideal para visitar entre mayo y septiembre\n",
      "\n",
      "¬øTe gustar√≠a que te cuente m√°s sobre Ljubljana o prefieres explorar otras opciones de destino?\n",
      "None\n",
      "--------\n",
      "Respuesta final:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Lo siento, parece que hay un problema t√©cnico con la b√∫squeda de informaci√≥n. Sin embargo, puedo compartir contigo algunos detalles sobre Ljubljana bas√°ndome en mi conocimiento:\n",
      "\n",
      "Ljubljana es una ciudad encantadora y poco conocida que ofrece una experiencia √∫nica de viaje:\n",
      "\n",
      "1. Arquitectura y ambiente:\n",
      "- Ciudad peque√±a y pintoresca\n",
      "- Dise√±o urbano influenciado por el arquitecto Jo≈æe Pleƒçnik\n",
      "- Centro hist√≥rico peatonal muy bien conservado\n",
      "\n",
      "2. Atracciones principales:\n",
      "- Castillo de Ljubljana: Una fortaleza medieval con vistas panor√°micas\n",
      "- Puente de los Dragones: Un s√≠mbolo emblem√°tico de la ciudad\n",
      "- Mercado central: Lugar perfecto para probar la gastronom√≠a local\n",
      "\n",
      "3. Entorno natural:\n",
      "- Rodeada de naturaleza impresionante\n",
      "- Cerca del Lago Bled, uno de los lugares m√°s hermosos de Europa\n",
      "- F√°cil acceso a parques nacionales y paisajes monta√±osos\n",
      "\n",
      "4. Ventajas para el viajero:\n",
      "- Destino menos tur√≠stico, lo que significa menos multitudes\n",
      "- Precios m√°s econ√≥micos comparados con otras capitales europeas\n",
      "- Gente amable y ambiente relajado\n",
      "- Excelente gastronom√≠a con influencias austriacas, italianas y balc√°nicas\n",
      "\n",
      "5. Clima:\n",
      "- Veranos suaves y agradables\n",
      "- Inviernos moderados\n",
      "- Ideal para visitar entre mayo y septiembre\n",
      "\n",
      "¬øTe gustar√≠a que te cuente m√°s sobre Ljubljana o prefieres explorar otras opciones de destino?\n",
      "None\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"user_id\": 918}}\n",
    "\n",
    "response = react_agent.invoke({\"messages\": [HumanMessage(content=\"Sugi√©reme un buen destino de vacaciones.\")]}, config)\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"Rastro completo:\")\n",
    "for one_message in response[\"messages\"]:\n",
    "    print(one_message.pretty_print())\n",
    "print(\"--------\")\n",
    "print(\"Respuesta final:\")\n",
    "print(response[\"messages\"][-1].pretty_print())\n",
    "print(\"--------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a9f6e-a3a8-49e0-b960-d2ae164590d7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Construir una cadena ReAct personalizada\n",
    "\n",
    "Como parte del *Enfoque 1*, vamos a explorar el uso de grafos (Graph o DAG - Directed Acyclic Graph) para dar m√°s **determinismo** al comportamiento de nuestros agentes. Este enfoque nos permitir√° tener **mayor control** sobre qu√© herramienta se llama y c√≥mo se utiliza.\n",
    "\n",
    "Hasta ahora hemos visto que el modelo LLM puede decidir qu√© herramienta utilizar.  \n",
    "Pero... ¬øqu√© pasa si necesitamos m√°s control sobre la transici√≥n entre nodos?  \n",
    "¬øQu√© pasa si una herramienta **no tiene todos los inputs necesarios** para ejecutarse?  \n",
    "¬øO si queremos **devolver directamente el resultado de la herramienta**, sin intervenci√≥n del LLM?\n",
    "\n",
    "En esta secci√≥n veremos c√≥mo construir un agente m√°s **personalizado y transparente** utilizando **LangGraph**, una librer√≠a que permite definir agentes mediante grafos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392850d-fc00-454f-9f7b-361c86bf1e8f",
   "metadata": {},
   "source": [
    "<img src=\"images/react_tool_call.png\" width=\"200\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397eb6d5-8fe6-4b24-aee2-dfe25e1146c8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Estado del agente\n",
    "\n",
    "El grafo que vamos a construir estar√° **parametrizado por un objeto de estado**, que se pasa entre nodos durante la ejecuci√≥n.  \n",
    "Este estado es mutable: cada nodo puede actualizarlo al procesar informaci√≥n.\n",
    "\n",
    "En este ejemplo, queremos que cada nodo agregue mensajes a una lista.  \n",
    "Para eso, definimos un `TypedDict` con una clave `messages` como parte del estado.\n",
    "\n",
    "Usaremos el operador `add_messages` para acumular el historial de mensajes mientras avanza la ejecuci√≥n del grafo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00901e7d-b1b7-4277-a030-cd6784e6f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ec760-435c-4e1a-944c-2735bc17ced8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Crear el Agente utilizando la cadena LCEL**\n",
    "\n",
    "En este paso se construye un **agente** utilizando la arquitectura de cadenas de procesamiento conocida como **LCEL** (*LangChain Expression Language*). Esta arquitectura permite construir flujos complejos de l√≥gica alrededor de modelos de lenguaje (LLMs) de manera estructurada y reutilizable.\n",
    "\n",
    "### **`bind_tools()` ‚Äì Vincular herramientas al agente**\n",
    "\n",
    "La funci√≥n `bind_tools()` se utiliza para **vincular herramientas externas** (como funciones, APIs, calculadoras, bases de datos, etc.) al agente. Esto permite que el agente no solo genere texto, sino que tambi√©n pueda **realizar acciones concretas**, como buscar informaci√≥n, realizar c√°lculos, interactuar con entornos externos, etc.\n",
    "\n",
    "### **Definir la funci√≥n del asistente**\n",
    "\n",
    "Se define una funci√≥n que representa al **asistente inteligente**. Esta funci√≥n realiza las siguientes tareas:\n",
    "\n",
    "1. **Toma el estado del grafo:**  \n",
    "   El \"estado del grafo\" representa la informaci√≥n actual sobre el contexto del di√°logo, las decisiones pasadas, entradas previas del usuario, herramientas disponibles, etc.\n",
    "\n",
    "2. **Formatea ese estado en un prompt:**  \n",
    "   Es decir, transforma toda esa informaci√≥n en una **entrada textual estructurada** que puede entender un modelo de lenguaje.\n",
    "\n",
    "3. **Llama a un modelo de lenguaje (LLM):**  \n",
    "   Se utiliza ese prompt como entrada para un LLM, que generar√° una **respuesta predictiva e inteligente** basada en el contexto dado.\n",
    "\n",
    "4. **Devuelve la mejor respuesta:**  \n",
    "   La salida del LLM es la respuesta m√°s adecuada, la cual se regresa como resultado de la funci√≥n del asistente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a4ff93-928d-480e-87af-63697a3c5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un asistente √∫til capaz de proporcionar recomendaciones de viaje.\"\n",
    "            \" Usa las herramientas proporcionadas para buscar recomendaciones personalizadas de viaje e informaci√≥n sobre destinos espec√≠ficos.\"\n",
    "            \" `compare_and_recommend_destination` tiene informaci√≥n sobre el usuario. Usa esta herramienta para obtener recomendaciones.\"\n",
    "            \" Si no tienes suficiente informaci√≥n, entonces usa la herramienta AskHuman para obtener la informaci√≥n necesaria.\"\n",
    "            \" Al buscar, s√© persistente. Ampl√≠a los l√≠mites de tu b√∫squeda si la primera b√∫squeda no devuelve resultados.\"\n",
    "            \" Si una b√∫squeda no produce resultados, ampl√≠a tu b√∫squeda antes de rendirte.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=model_id,\n",
    "    temperature=0,\n",
    "    max_tokens=5000,\n",
    "    client=bedrock_client,\n",
    ")\n",
    "runnable_with_tools = primary_assistant_prompt | llm.bind_tools(tools)\n",
    "\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    response = runnable_with_tools.invoke(state)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1845a9-d63d-4513-9560-e80233a802e3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Construcci√≥n del grafo**\n",
    "\n",
    "En nuestro caso, necesitamos definir una **arista condicional** que redirija al **ToolNode** cuando se invoque una herramienta desde el **agent node**, es decir, cuando el modelo LLM determine que se requiere el uso de una herramienta.  \n",
    "\n",
    "Con `tools_condition`, **LangGraph** proporciona una funci√≥n preimplementada que puede manejar esta l√≥gica de forma autom√°tica.  \n",
    "\n",
    "Adem√°s, se requiere una arista que vaya desde el nodo **START** hacia el **assistant**, as√≠ como otra que conecte de vuelta desde el **ToolNode** al **assistant**.\n",
    "\n",
    "Estamos a√±adiendo los **nodos**, **aristas** y tambi√©n una **memoria persistente** al **StateGraph**, antes de compilarlo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248d1826-44d2-42b2-aac0-27d7250b465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Definir nodos: estos realizan el trabajo\n",
    "graph_builder.add_node(\"travel_planner\", call_model)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "\n",
    "# Definir aristas: estas determinan c√≥mo se mueve el flujo de control\n",
    "graph_builder.add_edge(START, \"travel_planner\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"travel_planner\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"travel_planner\")\n",
    "\n",
    "# El checkpointer permite que el grafo persista su estado\n",
    "# Esta es una memoria completa para todo el grafo.\n",
    "memory = MemorySaver()\n",
    "travel_planner_agent = graph_builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843db886-c6c4-4224-8dd3-79db6c120cf6",
   "metadata": {},
   "source": [
    "Echemos un vistazo a una representaci√≥n visual de nuestro grafo de estado compilado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd4b28f-aacd-4b4d-b4b5-277c8a1cdb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(travel_planner_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f998c-dd32-4ce3-ac54-36df042d4849",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Es hora de probar nuestro grafo compilado. Podemos usar la entrada que ya hemos usado antes:\n",
    "\n",
    "**Sugi√©reme un buen destino de vacaciones.** --- pasa el ID de usuario 709.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4b5e497-775a-4a68-912f-2d3004a2e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Sugi√©reme un buen destino de vacaciones.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Voy a ayudarte a encontrar un destino de vacaciones perfecto. Primero, utilizar√© la herramienta de recomendaci√≥n de destinos para obtener una sugerencia personalizada.'}, {'type': 'tool_use', 'name': 'compare_and_recommend_destination', 'input': {}, 'id': 'tooluse_xcCvzJCMR26JjV4QAMK7Tg'}]\n",
      "Tool Calls:\n",
      "  compare_and_recommend_destination (tooluse_xcCvzJCMR26JjV4QAMK7Tg)\n",
      " Call ID: tooluse_xcCvzJCMR26JjV4QAMK7Tg\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: compare_and_recommend_destination\n",
      "\n",
      "Usuario no encontrado en la base de datos de viajes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Parece que no hay un historial de viajes previos para este usuario. En este caso, me gustar√≠a obtener m√°s informaci√≥n sobre tus preferencias para poder recomendarte un destino m√°s adecuado. \n",
      "\n",
      "¬øPodr√≠as decirme qu√© tipo de vacaciones te gustar√≠a? Por ejemplo:\n",
      "- ¬øPrefieres playa o monta√±a?\n",
      "- ¬øBuscas un destino cultural o m√°s de naturaleza?\n",
      "- ¬øTienes alg√∫n inter√©s especial como gastronom√≠a, historia, aventura?\n",
      "- ¬øHay alguna regi√≥n o pa√≠s que te gustar√≠a visitar?\n",
      "\n",
      "Cuanto m√°s espec√≠fico seas, mejor podr√© ayudarte a encontrar el destino perfecto para tus vacaciones.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"4\", \"user_id\": 193}}\n",
    "\n",
    "input_message = HumanMessage(\n",
    "    content=\"Sugi√©reme un buen destino de vacaciones.\"\n",
    ")\n",
    "for event in travel_planner_agent.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ea71e-cd0f-451f-99f1-eb38e58e3e5b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **Flujos agentes interactivos, Human-In-The-Loop ‚Äì Enfoque 2**\n",
    "\n",
    "\n",
    "**Interacci√≥n con el usuario durante la ejecuci√≥n para obtener entradas adicionales**\n",
    "\n",
    "A veces, se requiere entrada adicional para ejecutar una herramienta o resolver una tarea de nivel superior. O bien, podr√≠amos necesitar confirmaciones antes de ejecutar funciones cr√≠ticas. En estos casos, es necesario devolver el control al usuario para recopilar retroalimentaci√≥n humana.\n",
    "\n",
    "En **LangGraph**, esto se puede implementar mediante un concepto similar a un **punto de interrupci√≥n (breakpoint)**: se detiene la ejecuci√≥n del grafo en un paso espec√≠fico. En ese punto, podemos esperar entrada del usuario. Una vez que recibimos esa entrada, la a√±adimos al estado del grafo y reanudamos la ejecuci√≥n.\n",
    "\n",
    "En lo que sigue, extenderemos nuestro asistente agente para soportar interacci√≥n con el usuario a trav√©s de **ReWoO** (Return of Work Ownership) o **retorno de control**. Los sistemas en producci√≥n suelen utilizar la funci√≥n `interrupt_before`, donde el grafo se pausa temporalmente y devuelve un ID. Puedes leer m√°s sobre esto en la documentaci√≥n oficial.\n",
    "\n",
    "**En este taller, usaremos `MemorySaver` para simular ese comportamiento.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Interrupci√≥n para aprobaci√≥n**\n",
    "\n",
    "Estamos construyendo un sistema que gestiona diversas operaciones de hotel, como sugerencia de hoteles, recuperaci√≥n de reservas, modificaci√≥n de reservas y cancelaciones.  \n",
    "Un requisito clave es implementar **aprobaci√≥n humana para operaciones sensibles** (modificaciones y cancelaciones), mientras que se permite que otras operaciones se realicen autom√°ticamente.  \n",
    "Esto crea una divisi√≥n natural en el flujo de trabajo: operaciones autom√°ticas vs. operaciones que requieren supervisi√≥n humana.\n",
    "\n",
    "---\n",
    "\n",
    "### **Dos enfoques posibles para implementar esto:**\n",
    "\n",
    "| **Enfoque**                | **Descripci√≥n**                                                                                                                                                      | **Ventajas**                                                                                     | **Desventajas**                                                                                   |\n",
    "|---------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n",
    "| **Custom Tool Node**      | Basado en el prompt. Todo ocurre en un solo flujo donde la aprobaci√≥n humana se maneja mediante prompt engineering. El sistema decide si se necesita aprobaci√≥n.     | Estructura de grafo m√°s simple con menos nodos.<br>F√°cil de modificar sin cambiar el grafo.     | Riesgo alto de mala interpretaci√≥n del prompt.<br>Dif√≠cil de depurar errores en el prompt.         |\n",
    "| **Separated Node Approach** | Flujo separado: un camino para operaciones rutinarias y otro para operaciones sensibles que requieren aprobaci√≥n.                                                     | Flujo determinista y claro en el grafo.<br>Separaci√≥n l√≥gica entre operaciones.                | Requiere m√°s gesti√≥n de estado.<br>Estructura del grafo m√°s compleja.                             |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3785c1-608d-4f3f-998a-42ab10dd9a4c",
   "metadata": {},
   "source": [
    "<img src=\"images/human-in-the-loop.png\" width=\"200\" height=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f35fcac-70e5-4cf7-884d-46e889ed65d7",
   "metadata": {},
   "source": [
    "**üîß En este taller, demostraremos el enfoque de `Custom Tool Node` y lo usaremos como base.**\n",
    "\n",
    "> üìå Nota: Consulta el ejemplo en el notebook `DO_NOT_run` para ver un ejemplo de interrupci√≥n del estado del grafo.\n",
    "\n",
    "---\n",
    "\n",
    "### **Custom Tool Node para Aprobaci√≥n Humana**\n",
    "\n",
    "- Nodo de aprobaci√≥n personalizado que regula el acceso a operaciones sensibles.  \n",
    "- Recolecci√≥n de entrada humana de forma s√≠ncrona.  \n",
    "- Ejecuci√≥n directa de la herramienta tras la aprobaci√≥n.  \n",
    "- Flujo lineal sin necesidad de manejar estados complejos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f9ff9b2-8955-4f9b-9e8b-a12096373f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class HumanApprovalToolNode:\n",
    "    \"\"\"Un nodo que ejecuta herramientas solicitadas en el √∫ltimo AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        # Crea un diccionario de herramientas por nombre para invocarlas f√°cilmente\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        # Extrae los mensajes del estado de entrada\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]  # Toma el √∫ltimo mensaje\n",
    "        else:\n",
    "            raise ValueError(\"No se encontr√≥ ning√∫n mensaje en la entrada\")\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        # Itera sobre cada llamada de herramienta solicitada\n",
    "        for tool_call in message.tool_calls:\n",
    "            # Solicita aprobaci√≥n del usuario antes de ejecutar\n",
    "            user_input = input(\n",
    "                \"¬øApruebas las acciones anteriores? Escribe 'y' para continuar; \"\n",
    "                \"de lo contrario, explica los cambios que solicitas.\\n\\n\"\n",
    "            )\n",
    "\n",
    "            if user_input.lower() == \"y\":\n",
    "                # Si se aprueba, ejecuta la herramienta y guarda el resultado\n",
    "                tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "                outputs.append(\n",
    "                    ToolMessage(\n",
    "                        content=json.dumps(tool_result),\n",
    "                        name=tool_call[\"name\"],\n",
    "                        tool_call_id=tool_call[\"id\"],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # Si se rechaza, responde con la raz√≥n y contin√∫a asistiendo\n",
    "                outputs.append(\n",
    "                    ToolMessage(\n",
    "                        content=f\"Llamada a API denegada por el usuario. Motivo: '{user_input}'. Contin√∫a asistiendo, considerando la entrada del usuario.\",\n",
    "                        name=tool_call[\"name\"],\n",
    "                        tool_call_id=tool_call[\"id\"],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return {\"messages\": outputs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731da53-9b51-465f-9150-13d7b2964d1b",
   "metadata": {},
   "source": [
    "\n",
    "Compilamos nuevamente el grafo, pero esta vez, en lugar de usar el `ToolNode` preconstruido, utilizaremos el `HumanApprovalToolNode` que hemos creado para permitir la aprobaci√≥n humana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "675a07de-f131-4901-84e3-b5639f98957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# Define nodes: these do the work\n",
    "graph_builder.add_edge(START, \"travel_planner\")\n",
    "graph_builder.add_node(\"travel_planner\", call_model)\n",
    "graph_builder.add_node(\"tools\", HumanApprovalToolNode(tools=tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"travel_planner\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"travel_planner\")\n",
    "\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# this is a complete memory for the entire graph.\n",
    "memory = MemorySaver()\n",
    "agent_with_hil = graph_builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bab09-29fe-4c8b-a647-9c9d494e79dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf31ef5-7e87-4f16-96f2-bf3ec9126896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent_with_hil.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b0e9a-46d1-4a9a-8804-96e630b27e2a",
   "metadata": {},
   "source": [
    "¬°Vamos a probarlo!\n",
    "\n",
    "Cuando ejecutes esta celda, ver√°s un mensaje solicitando confirmaci√≥n como:  \n",
    "**\"¬øApruebas las acciones anteriores? Escribe 'y' para continuar;\"**  \n",
    "Por favor, escribe **y** para continuar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86109dd7-c742-4a39-802c-83ce98e0dbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Sugi√©reme un buen destino de vacaciones.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Voy a ayudarte a encontrar un destino de vacaciones perfecto. Primero, utilizar√© la herramienta de recomendaci√≥n de destinos para obtener una sugerencia personalizada.'}, {'type': 'tool_use', 'name': 'compare_and_recommend_destination', 'input': {}, 'id': 'tooluse_E6LiaMHdQION7UDvBfbCHA'}]\n",
      "Tool Calls:\n",
      "  compare_and_recommend_destination (tooluse_E6LiaMHdQION7UDvBfbCHA)\n",
      " Call ID: tooluse_E6LiaMHdQION7UDvBfbCHA\n",
      "  Args:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¬øApruebas las acciones anteriores? Escribe 'y' para continuar; de lo contrario, explica los cambios que solicitas.\n",
      "\n",
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: compare_and_recommend_destination\n",
      "\n",
      "\"Basado en tu ubicaci\\u00f3n actual (Baltimore), edad (48.0) y tu historial de viajes, te recomendamos visitar St. Louis.\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'St. Louis parece ser una excelente recomendaci√≥n. Voy a buscar m√°s informaci√≥n sobre esta ciudad para darte m√°s detalles:'}, {'type': 'tool_use', 'name': 'search_user_interest', 'input': {'query': 'St. Louis turismo atracciones'}, 'id': 'tooluse_gs1QWXTvSjq96oHa3pjhwQ'}]\n",
      "Tool Calls:\n",
      "  search_user_interest (tooluse_gs1QWXTvSjq96oHa3pjhwQ)\n",
      " Call ID: tooluse_gs1QWXTvSjq96oHa3pjhwQ\n",
      "  Args:\n",
      "    query: St. Louis turismo atracciones\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¬øApruebas las acciones anteriores? Escribe 'y' para continuar; de lo contrario, explica los cambios que solicitas.\n",
      "\n",
      " y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error raised by inference endpoint\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py\", line 195, in _invoke_model\n",
      "    response = self.client.invoke_model(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py\", line 570, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ec2-user/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py\", line 1031, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m input_message = HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mSugi√©reme un buen destino de vacaciones.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Ejecuci√≥n del agente con flujo interactivo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43magent_with_hil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_message\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2433\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2427\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2428\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2429\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2430\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2431\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2432\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2434\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mHumanApprovalToolNode.__call__\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m     23\u001b[39m user_input = \u001b[38;5;28minput\u001b[39m(\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m¬øApruebas las acciones anteriores? Escribe \u001b[39m\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m\u001b[33m para continuar; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mde lo contrario, explica los cambios que solicitas.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_input.lower() == \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Si se aprueba, ejecuta la herramienta y guarda el resultado\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     tool_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtools_by_name\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool_call\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_call\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43margs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     outputs.append(\n\u001b[32m     32\u001b[39m         ToolMessage(\n\u001b[32m     33\u001b[39m             content=json.dumps(tool_result),\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m         )\n\u001b[32m     37\u001b[39m     )\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Si se rechaza, responde con la raz√≥n y contin√∫a asistiendo\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/tools/base.py:513\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    507\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs: Any,\n\u001b[32m    511\u001b[39m ) -> Any:\n\u001b[32m    512\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/tools/base.py:774\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    773\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    775\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    776\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/tools/base.py:743\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    742\u001b[39m         tool_kwargs = tool_kwargs | {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    745\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/tools/simple.py:105\u001b[39m, in \u001b[36mTool._run\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m    104\u001b[39m         kwargs[config_param] = config\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mTool does not support sync invocation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/tools/retriever.py:38\u001b[39m, in \u001b[36m_get_relevant_documents\u001b[39m\u001b[34m(query, retriever, document_prompt, document_separator, callbacks, response_format)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_relevant_documents\u001b[39m(\n\u001b[32m     31\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     32\u001b[39m     retriever: BaseRetriever,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     response_format: Literal[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m ) -> Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Document]]]:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     docs = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     content = document_separator.join(\n\u001b[32m     40\u001b[39m         format_document(doc, document_prompt) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs\n\u001b[32m     41\u001b[39m     )\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/retrievers.py:258\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m _kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    262\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain/retrievers/multi_vector.py:78\u001b[39m, in \u001b[36mMultiVectorRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager)\u001b[39m\n\u001b[32m     76\u001b[39m     sub_docs = [sub_doc \u001b[38;5;28;01mfor\u001b[39;00m sub_doc, _ \u001b[38;5;129;01min\u001b[39;00m sub_docs_and_similarities]\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     sub_docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# We do this to maintain the order of the ids that are returned\u001b[39;00m\n\u001b[32m     81\u001b[39m ids = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:641\u001b[39m, in \u001b[36mFAISS.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    622\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    623\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    627\u001b[39m     **kwargs: Any,\n\u001b[32m    628\u001b[39m ) -> List[Document]:\n\u001b[32m    629\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    630\u001b[39m \n\u001b[32m    631\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    639\u001b[39m \u001b[33;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    644\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:513\u001b[39m, in \u001b[36mFAISS.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search_with_score\u001b[39m(\n\u001b[32m    490\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    491\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    495\u001b[39m     **kwargs: Any,\n\u001b[32m    496\u001b[39m ) -> List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    497\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    498\u001b[39m \n\u001b[32m    499\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    511\u001b[39m \u001b[33;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m     embedding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m     docs = \u001b[38;5;28mself\u001b[39m.similarity_search_with_score_by_vector(\n\u001b[32m    515\u001b[39m         embedding,\n\u001b[32m    516\u001b[39m         k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m         **kwargs,\n\u001b[32m    520\u001b[39m     )\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:265\u001b[39m, in \u001b[36mFAISS._embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_embed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.embedding_function, Embeddings):\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    267\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embedding_function(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py:262\u001b[39m, in \u001b[36mBedrockEmbeddings.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    260\u001b[39m     embedding = \u001b[38;5;28mself\u001b[39m._embedding_func(text, input_type=\u001b[33m\"\u001b[39m\u001b[33msearch_query\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     embedding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.normalize:\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._normalize_vector(embedding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py:164\u001b[39m, in \u001b[36mBedrockEmbeddings._embedding_func\u001b[39m\u001b[34m(self, text, input_type)\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_body.get(\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# includes common provider == \"amazon\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     response_body = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minputText\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_body.get(\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py:206\u001b[39m, in \u001b[36mBedrockEmbeddings._invoke_model\u001b[39m\u001b[34m(self, input_body)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     logger.exception(\u001b[33m\"\u001b[39m\u001b[33mError raised by inference endpoint\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_aws/embeddings/bedrock.py:195\u001b[39m, in \u001b[36mBedrockEmbeddings._invoke_model\u001b[39m\u001b[34m(self, input_body)\u001b[39m\n\u001b[32m    192\u001b[39m body = json.dumps(input_body)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontentType\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     response_body = json.loads(response.get(\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m).read())\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_body\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py:570\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    567\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    568\u001b[39m     )\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py:1031\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1027\u001b[39m     error_code = error_info.get(\u001b[33m\"\u001b[39m\u001b[33mQueryErrorCode\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\n\u001b[32m   1028\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1029\u001b[39m     )\n\u001b[32m   1030\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.",
      "During task with name 'tools' and id 'da40843f-1d4f-ca9f-5201-812dbc548c94'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Configuraci√≥n del hilo y usuario\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"10\",\n",
    "        \"user_id\": 118\n",
    "    },\n",
    "    \"recursion_limit\": 10,\n",
    "}\n",
    "\n",
    "# Mensaje de entrada del usuario\n",
    "input_message = HumanMessage(content=\"Sugi√©reme un buen destino de vacaciones.\")\n",
    "\n",
    "# Ejecuci√≥n del agente con flujo interactivo\n",
    "for event in agent_with_hil.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15640693-14e5-4f27-ad58-3a93753bf33a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Agente multimodal**\n",
    "\n",
    "Veamos un escenario en el que tambi√©n podemos procesar im√°genes como entrada para nuestro agente. Vamos a crear un agente capaz de analizar im√°genes utilizando **Claude 3 Haiku**, el modelo multimodal m√°s r√°pido de Anthropic.\n",
    "\n",
    "El flujo de trabajo es sencillo: los usuarios suben una imagen de un lugar que les gustar√≠a visitar, y nuestro agente entra en acci√≥n. Utilizando las capacidades de visi√≥n de Claude 3 Haiku, identifica la ciudad o el monumento que aparece en la imagen. Luego, utiliza una herramienta de recuperaci√≥n personalizada que contiene informaci√≥n detallada sobre distintas ciudades para ofrecer recomendaciones y datos relevantes sobre el destino.\n",
    "\n",
    "Vamos a reutilizar el *retriever* que ya creamos anteriormente. Solo actualizaremos el nombre y la descripci√≥n de la herramienta para asegurar que el modelo pueda usarla correctamente.\n",
    "\n",
    "Usaremos esta imagen para pedir al sistema agente que recomiende destinos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69ac48-38d7-4da0-8b91-cf56826bc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d477fa0-da8b-4089-837f-07d20153729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_info_retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"city_info_retriever_tool\",\n",
    "    \"Busca a trav√©s de m√∫ltiples documentos PDF que contienen detalles de ciudades para encontrar informaci√≥n que coincida con los intereses del usuario en diversas ciudades.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14565ed6-296a-4b0b-a9f9-759246efc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vincula la herramienta al modelo\n",
    "model_with_tools = llm.bind_tools([city_info_retriever_tool])\n",
    "\n",
    "# Crea un agente de reacci√≥n (React Agent) con la herramienta vinculada\n",
    "dream_destination_agent = create_react_agent(llm,tools=[city_info_retriever_tool,])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d6980-75a7-4a0b-b35b-7d5a0b8ad97b",
   "metadata": {},
   "source": [
    "Aqu√≠ haremos una b√∫squeda multimodal usando nuestra herramienta dream_destination_agent. Recuerda, si recibes un error como el siguiente, aseg√∫rate de haber solicitado acceso al modelo Titan que estamos utilizando para las incrustaciones: Esto es en caso de que veas un error como este --- > Ocurri√≥ un error (AccessDeniedException) al llamar a la operaci√≥n InvokeModel: No tienes acceso al modelo con el ID de modelo especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88895282-7007-4c89-bc6d-94791394b022",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the Converse operation: This model doesn't support the image content block that you provided. Update the content block and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      5\u001b[39m     image_data = base64.b64encode(image_file.read()).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m message = HumanMessage(\n\u001b[32m      8\u001b[39m     content=[\n\u001b[32m      9\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGive more details about the city\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     ],\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m result_msg = \u001b[43mdream_destination_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     17\u001b[39m result_msg[-\u001b[32m1\u001b[39m].pretty_print()\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# - un comment if you want to see the whole sequence of calls, just be aware this will  print the base 64 encoded image string as well -- \u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# print(result_msg)#\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2795\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2793\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2794\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2795\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2796\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2799\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2800\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2801\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2804\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2805\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2806\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2807\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2433\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2427\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2428\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2429\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2430\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2431\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2432\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2434\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langgraph/prebuilt/chat_agent_executor.py:745\u001b[39m, in \u001b[36mcreate_react_agent.<locals>.call_model\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) -> StateSchema:\n\u001b[32m    744\u001b[39m     state = _get_model_input_state(state)\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     response = cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    746\u001b[39m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[32m    747\u001b[39m     response.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/runnables/base.py:3034\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3033\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3034\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[32m   3035\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/runnables/base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:369\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    359\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    364\u001b[39m     **kwargs: Any,\n\u001b[32m    365\u001b[39m ) -> BaseMessage:\n\u001b[32m    366\u001b[39m     config = ensure_config(config)\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    368\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    379\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:946\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    937\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    939\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    943\u001b[39m     **kwargs: Any,\n\u001b[32m    944\u001b[39m ) -> LLMResult:\n\u001b[32m    945\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:765\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    763\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    764\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m         )\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    773\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1011\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1009\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1015\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/langchain_aws/chat_models/bedrock_converse.py:650\u001b[39m, in \u001b[36mChatBedrockConverse._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    648\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    649\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mUsing Bedrock Converse API to generate response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbedrock_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResponse from Bedrock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    654\u001b[39m response_message = _parse_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py:570\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    567\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    568\u001b[39m     )\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mi_entorno_311/lib/python3.11/site-packages/botocore/client.py:1031\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1027\u001b[39m     error_code = error_info.get(\u001b[33m\"\u001b[39m\u001b[33mQueryErrorCode\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\n\u001b[32m   1028\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1029\u001b[39m     )\n\u001b[32m   1030\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the Converse operation: This model doesn't support the image content block that you provided. Update the content block and try again.",
      "During task with name 'agent' and id 'f63cf72c-eaae-9d05-ce92-07bf7aded445'"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "image_url = \"images/amsterdam.jpeg\"\n",
    "with open(image_url, 'rb') as image_file:\n",
    "    image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Give more details about the city\"},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "result_msg = dream_destination_agent.invoke({\"messages\": [message]})['messages']\n",
    "result_msg[-1].pretty_print()\n",
    "\n",
    "# - un comment if you want to see the whole sequence of calls, just be aware this will  print the base 64 encoded image string as well -- \n",
    "# print(result_msg)#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e831e-0eae-41c9-85c8-9bb9c3eea55a",
   "metadata": {},
   "source": [
    "Let us see what our Vector store returned from this Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b29da7a-5a9b-4593-a0a4-bbcb37110b00",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_msg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult_msg\u001b[49m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(i) == ToolMessage:\n\u001b[32m      3\u001b[39m         \u001b[38;5;28mprint\u001b[39m(i.content)\n",
      "\u001b[31mNameError\u001b[39m: name 'result_msg' is not defined"
     ]
    }
   ],
   "source": [
    "for i in result_msg:\n",
    "    if type(i) == ToolMessage:\n",
    "        print(i.content)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb6f2d-ede9-4e98-a998-443cd4d2499a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mi_entorno_311)",
   "language": "python",
   "name": "mi_entorno_311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
